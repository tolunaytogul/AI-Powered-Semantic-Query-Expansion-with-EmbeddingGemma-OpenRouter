# =============================================================
# ğŸ”¹ SEO Query Fan-Out & Cosine Similarity Tool (Colab Version)
# =============================================================

# ==============================================
# ğŸ§© GEREKLÄ° KÃœTÃœPHANELERÄ° YÃœKLE
# ==============================================
!pip install -q sentence-transformers openai numpy scikit-learn pandas

from openai import OpenAI
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd
import re, time

# ==============================================
# ğŸ” HUGGINGFACE TOKEN & OPENROUTER API ANAHTARLARI
# ==============================================
HF_TOKEN = "hf_xxxxxxxx"  # ğŸ‘ˆ HuggingFace token'Ä±nÄ± buraya yaz
OPENROUTER_KEYS = {
    "llama4":  "sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
    "deepseek":"sk-or-v1-yyyyyyyyyyyyyyyyyyyyyyyyyyyyyy",
    "qwen":    "sk-or-v1-zzzzzzzzzzzzzzzzzzzzzzzzzzzzzz"
}

# ==============================================
# ğŸ§  EMBEDDINGGEMMA MODELÄ°NÄ° YÃœKLE
# ==============================================
embedding_model = SentenceTransformer(
    "google/embeddinggemma-300m",
    cache_folder="/content/cache",
    use_auth_token=HF_TOKEN
)
print("âœ… EmbeddingGemma baÅŸarÄ±yla yÃ¼klendi!")

# ==============================================
# âš™ï¸ OPENROUTER MODELLERÄ°
# ==============================================
MODELS = {
    "llama4":  "meta-llama/llama-4-maverick:free",
    "deepseek":"deepseek/deepseek-chat-v3.1:free",
    "qwen":    "qwen/qwen3-14b:free"
}

clients = {
    name: OpenAI(base_url="https://openrouter.ai/api/v1", api_key=key)
    for name, key in OPENROUTER_KEYS.items()
}
print("âœ… OpenRouter modelleri yÃ¼klendi:", list(clients.keys()))

# ==============================================
# ğŸ’¬ QUERY FAN-OUT OLUÅTURMA
# ==============================================
def generate_fanout_queries(seed_query, n=15, max_retries=3):
    """
    Anahtar kelimeden 15 farklÄ± Google tarzÄ± sorgu Ã¼retir.
    """
    prompt = f"""
    Sen deneyimli bir SEO uzmanÄ±sÄ±n.
    AÅŸaÄŸÄ±daki anahtar kelimeden {n} farklÄ±, doÄŸal Google arama sorgusu Ã¼ret.
    Dil otomatik olarak algÄ±lansÄ±n ve aynÄ± dilde Ã¼retim yap.

    Anahtar kelime:
    "{seed_query}"

    ğŸ”¹ Kurallar:
    - Bilgilendirici, yÃ¶nlendirici, ticari ve iÅŸlemsel sorgular dengeli olmalÄ±.
    - Kopya veya benzer sorgular Ã¼retme.
    - YalnÄ±zca numaralÄ± liste olarak Ã§Ä±ktÄ± ver.
    """

    for model_name in ["llama4", "deepseek", "qwen"]:
        for attempt in range(max_retries):
            try:
                print(f"âš™ï¸ KullanÄ±lan model: {model_name} (deneme {attempt+1})")
                client = clients[model_name]
                response = client.chat.completions.create(
                    model=MODELS[model_name],
                    messages=[{"role": "user", "content": prompt}],
                    temperature=1.0,
                    max_tokens=400
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"âŒ {model_name} baÅŸarÄ±sÄ±z: {e}")
                if attempt < max_retries - 1:
                    print("ğŸ” Tekrar deneniyor...")
                    time.sleep(5)
                else:
                    print("â³ Sonraki modele geÃ§iliyor...")
                    time.sleep(2)
                    break
    raise RuntimeError("ğŸš¨ TÃ¼m modeller baÅŸarÄ±sÄ±z oldu. Token veya limitleri kontrol edin.")

# ==============================================
# ğŸ“ˆ COSINE SIMILARITY HESAPLAMA
# ==============================================
def analyze_similarity(seed_query, generated_text):
    """
    Anahtar kelime ile Ã¼retilen sorgular arasÄ±ndaki semantik benzerliÄŸi hesaplar.
    """
    lines = [re.sub(r"^\d+\.\s*", "", l).strip() for l in generated_text.split("\n") if len(l.strip()) > 3]
    queries = [seed_query] + lines

    embeddings = embedding_model.encode(queries)
    base_emb = embeddings[0].reshape(1, -1)
    scores = cosine_similarity(base_emb, embeddings[1:])[0]

    results = sorted(zip(queries[1:], scores), key=lambda x: -x[1])
    print("\nğŸ” Cosine Similarity SonuÃ§larÄ±:")
    for q, s in results:
        print(f"{q} â†’ {s:.3f}")

    return pd.DataFrame(results, columns=["Sorgu", "Cosine_Benzerlik"])

# ==============================================
# ğŸš€ Ã‡ALIÅTIRMA BLOÄU
# ==============================================
RUN_MULTI = False   # ğŸ‘ˆ True = birden fazla sorgu / False = tek sorgu
all_results = []

if not RUN_MULTI:
    seed_query = "seo danÄ±ÅŸmanlÄ±ÄŸÄ±"   # ğŸ‘ˆ Buraya sorgunu yaz
    print(f"\nğŸ”¹ Anahtar Kelime: {seed_query}")
    generated = generate_fanout_queries(seed_query, n=15)
    df = analyze_similarity(seed_query, generated)
    df["Anahtar_Kelime"] = seed_query
    all_results.append(df)
else:
    seed_queries = ["seo hizmeti", "e-ticaret seo", "yerel seo danÄ±ÅŸmanlÄ±ÄŸÄ±"]
    for query in seed_queries:
        print("\n==============================")
        print(f"ğŸ”¹ Anahtar Kelime: {query}")
        generated = generate_fanout_queries(query, n=15)
        df = analyze_similarity(query, generated)
        df["Anahtar_Kelime"] = query
        all_results.append(df)
        time.sleep(2)

# ==============================================
# ğŸ’¾ SONUÃ‡LARI KAYDET
# ==============================================
final_df = pd.concat(all_results, ignore_index=True)
final_df.to_csv("query_fanout_results.csv", index=False)
print("\nğŸ“ SonuÃ§lar kaydedildi: query_fanout_results.csv")
